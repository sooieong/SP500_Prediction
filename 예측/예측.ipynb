{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea524bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ\n",
    "model_path = \"../ë²„ì „2(SPY)/modeling/Model/ë‹¤ì¤‘íšŒê·€_best.joblib\"\n",
    "\n",
    "# ì˜ˆì¸¡ ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "data_path = \"../ì˜ˆì¸¡/SPYlogìƒ˜í”Œë°ì´í„°.csv\"\n",
    "\n",
    "try:\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    print(\"âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "    # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ë˜ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™í•˜ì§€ ì•ŠìŒ\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8131f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ. ë°ì´í„°ì…‹ ì •ë³´:\n",
      "   Unnamed: 0        Date  GC=F_Volume  ^VIX_Volatility  GC=F_Volatility  \\\n",
      "0           0  2025-11-10     5.241747         0.797507         3.947386   \n",
      "1           1  2025-11-11     6.343880         0.565314         3.505566   \n",
      "2           2  2025-11-12     5.981414         0.672944         4.620059   \n",
      "3           3  2025-11-13     5.117994         1.568616         4.174387   \n",
      "4           4  2025-11-14     6.180017         1.497389         5.016617   \n",
      "\n",
      "   SHY_Volatility  SPY_Premium_pct  y_target_log  \n",
      "0        0.029558         0.025857      6.524208  \n",
      "1        0.039222         0.047590      6.526495  \n",
      "2        0.029565         0.036686      6.527051  \n",
      "3        0.029558         0.028242      6.510318  \n",
      "4        0.086174         0.041819      6.510154  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_predict = pd.read_csv(data_path)\n",
    "    print(\"âœ… ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ. ë°ì´í„°ì…‹ ì •ë³´:\")\n",
    "    print(df_predict.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "050a0024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ. Shape: (7, 9)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. ì „ì—­ ë³€ìˆ˜ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„\n",
    "# -------------------------------\n",
    "\n",
    "# [ì¤‘ìš”] í•™ìŠµ ì‹œ ìµœì ìœ¼ë¡œ ë„ì¶œëœ seq_len ê°’ì„ ì§ì ‘ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì˜ˆì‹œì—ì„œëŠ” ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ì‹¤ì œ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!\n",
    "BEST_SEQ_LEN = 2 \n",
    "\n",
    "# -------------------------------\n",
    "# 1. ì „ì—­ ë³€ìˆ˜ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„ (ìˆ˜ì •ëœ ë¶€ë¶„)\n",
    "# -------------------------------\n",
    "\n",
    "price_col = \"y_target_log\"\n",
    "\n",
    "# 'Unnamed: 0', 'y_target_log' ì™¸ì— 'Date'ë„ í”¼ì²˜ì—ì„œ ì œì™¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì˜ˆì¸¡ ë°ì´í„°ì— 'Date' ì¹¼ëŸ¼ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ drop_colsì— í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "drop_cols = [\"Unnamed: 0\", price_col, \"Date\"] \n",
    "\n",
    "# X_predictëŠ” ì˜¤ì§ ìˆ«ìí˜• í”¼ì²˜ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "X_predict = df_predict.drop(columns=drop_cols, errors='ignore') \n",
    "y_log_predict = df_predict[price_col]\n",
    "\n",
    "# [ì¤‘ìš”] X_predictì˜ ëª¨ë“  ì¹¼ëŸ¼ì´ ìˆ«ìí˜•ì¸ì§€ ìµœì¢… í™•ì¸\n",
    "# (ë§Œì•½ ë‹¤ë¥¸ ë¬¸ìì—´ í”¼ì²˜ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ì˜¤ë¥˜ê°€ ë‹¤ì‹œ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n",
    "X_predict = X_predict.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# X_predictê°€ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ MinMaxScalerë¡œ ìŠ¤ì¼€ì¼ë§ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "scaler_seq = MinMaxScaler()\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ì™€ ì˜ˆì¸¡ ë°ì´í„°ì˜ í”¼ì²˜ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# (Date ì¹¼ëŸ¼ ì œê±° í›„)\n",
    "X_predict_scaled = scaler_seq.fit_transform(X_predict.values) \n",
    "\n",
    "print(f\"âœ… í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ. Shape: {X_predict_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e99a5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ. Shape: (7, 5)\n",
      "âœ… í˜„ì¬ ì´ í”¼ì²˜ ìˆ˜: 5\n"
     ]
    }
   ],
   "source": [
    "# 1-1. í•™ìŠµ ì‹œ ì‚¬ìš©ëœ 5ê°œ í”¼ì²˜ ì´ë¦„ì„ ì—¬ê¸°ì— ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# [ì‚¬ìš©ì ë³€ê²½ í•„ìš”]\n",
    "FEATURE_COLUMNS_FOR_PREDICTION = ['GC=F_Volume', '^VIX_Volatility', 'GC=F_Volatility', 'SHY_Volatility', 'SPY_Premium_pct'] \n",
    "# -------------------------------------------------------------\n",
    "\n",
    "price_col = \"y_target_log\"\n",
    "drop_cols = [\"Unnamed: 0\", price_col, \"Date\"] \n",
    "\n",
    "# 1. 'y_target_log' (ë¡œê·¸ ë ˆë²¨) ë¶„ë¦¬\n",
    "y_log_predict = df_predict[price_col]\n",
    "\n",
    "# 2. í”¼ì²˜ì—ì„œ ë¶ˆí•„ìš”í•œ ì—´ ì œê±°\n",
    "X_all = df_predict.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# 3. [í•µì‹¬ ìˆ˜ì •] í•™ìŠµì— ì‚¬ìš©ëœ 5ê°œ í”¼ì²˜ë§Œ ì„ íƒ\n",
    "#    (FEATURE_COLUMNS_FOR_PREDICTION ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ 9ê°œ ì¤‘ 5ê°œë§Œ ë‚¨ê¹€)\n",
    "X_predict = X_all[FEATURE_COLUMNS_FOR_PREDICTION] \n",
    "\n",
    "# 4. ìˆ«ìí˜• í”¼ì²˜ë§Œ ìµœì¢… í™•ì¸ (ì„ íƒëœ 5ê°œ í”¼ì²˜ëŠ” ëª¨ë‘ ìˆ«ìí˜•ì´ì–´ì•¼ í•¨)\n",
    "X_predict = X_predict.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# X_predictê°€ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ MinMaxScalerë¡œ ìŠ¤ì¼€ì¼ë§ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "scaler_seq = MinMaxScaler()\n",
    "\n",
    "# ì´ì œ X_predictì˜ shapeëŠ” (7, 5)ê°€ ë  ê²ƒì´ë©°, \n",
    "# ì‹œí€€ìŠ¤ ë³€í™˜ í›„ (7-2+1=6) ìƒ˜í”Œì˜ shapeëŠ” (6, 5*2=10)ì´ ë˜ì–´ ëª¨ë¸ ê¸°ëŒ€ì¹˜ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.\n",
    "X_predict_scaled = scaler_seq.fit_transform(X_predict.values) \n",
    "\n",
    "print(f\"âœ… í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ. Shape: {X_predict_scaled.shape}\")\n",
    "print(f\"âœ… í˜„ì¬ ì´ í”¼ì²˜ ìˆ˜: {X_predict_scaled.shape[1]}\") # 5ì—¬ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "877f370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ì¬êµ¬ì„± ì™„ë£Œ.\n",
      "   ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜: 6\n",
      "   ëª¨ë¸ ì…ë ¥ shape: (6, 10)\n",
      "âœ… ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ. ì˜ˆì¸¡ëœ ret_prev ê¸¸ì´: 6\n",
      "\n",
      "=== ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ (ë¡œê·¸ ë° ì‹¤ì œ ê°€ê²© ë ˆë²¨ - ì• 5ê°œ) ===\n",
      "            log_true  log_pred  Price_pred\n",
      "Date                                      \n",
      "2025-11-11  6.526495  6.533879  688.062366\n",
      "2025-11-12  6.527051  6.532389  687.037840\n",
      "2025-11-13  6.510318  6.502512  666.814325\n",
      "2025-11-14  6.510154  6.510263  672.003450\n",
      "2025-11-17  6.500794  6.500677  665.591945\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬/ëª¨ë“ˆì´ ì´ë¯¸ ìƒë‹¨ì— ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "# ì˜ˆ: import numpy as np, import pandas as pd, loaded_model ë³€ìˆ˜ ì¡´ì¬\n",
    "\n",
    "# -------------------------------\n",
    "# 2. ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜ ì¬ì •ì˜\n",
    "# -------------------------------\n",
    "def make_seq_dataset_for_reg(X_array, y_array, seq_len):\n",
    "    \"\"\"\n",
    "    X_array: (N, num_features)\n",
    "    y_array: (N,)\n",
    "    seq_len ê¸°ê°„ë§Œí¼ windowë¥¼ ë§Œë“¤ì–´,\n",
    "      X_seq: (num_samples, seq_len, num_features)\n",
    "      y_seq: (num_samples,)\n",
    "    ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. íƒ€ê¹ƒì€ windowì˜ ë§ˆì§€ë§‰ ì‹œì  y.\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë°ì´í„°ì˜ ê²½ìš°, ëª¨ë“  ì‹œí€€ìŠ¤ ìƒì„± ê°€ëŠ¥ ì‹œì ë¶€í„° ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    for i in range(len(X_array) - seq_len + 1):\n",
    "        X_list.append(X_array[i : i + seq_len])\n",
    "        # y_arrayëŠ” ì˜ˆì¸¡ ì‹œì ì˜ ì‹¤ì œ ë¡œê·¸ ë ˆë²¨(Ground Truth)ì…ë‹ˆë‹¤.\n",
    "        y_list.append(y_array[i + seq_len - 1]) \n",
    "        \n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. ì‹œí€€ìŠ¤ ë³€í™˜ ë° ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "# -------------------------------\n",
    "\n",
    "# X_predict_scaled (Shape: (7, 9))ì™€ y_log_predictë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "# BEST_SEQ_LEN = 2\n",
    "X_seq_predict, y_seq_true = make_seq_dataset_for_reg(\n",
    "    X_predict_scaled, \n",
    "    y_log_predict.values, \n",
    "    BEST_SEQ_LEN\n",
    ")\n",
    "n_samples = len(X_seq_predict) # ì˜ˆìƒ n_samples: 7 - 2 + 1 = 6\n",
    "\n",
    "if n_samples == 0:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: ì‹œí€€ìŠ¤ ìƒ˜í”Œ ìˆ˜ê°€ 0ì…ë‹ˆë‹¤. (ë°ì´í„° ê¸¸ì´:{len(X_predict_scaled)} vs BEST_SEQ_LEN:{BEST_SEQ_LEN})\")\n",
    "else:\n",
    "    # 3D (n_samples, seq_len, n_features) â†’ 2D (n_samples, seq_len * n_features)\n",
    "    X_predict_2d = X_seq_predict.reshape(n_samples, -1)\n",
    "    \n",
    "    print(f\"âœ… ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ ì¬êµ¬ì„± ì™„ë£Œ.\")\n",
    "    print(f\"   ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜: {n_samples}\")\n",
    "    print(f\"   ëª¨ë¸ ì…ë ¥ shape: {X_predict_2d.shape}\")\n",
    "\n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰ (ì°¨ë¶„ ê°’ ret_prev ì˜ˆì¸¡)\n",
    "    # loaded_modelì€ LinearRegression ëª¨ë¸ì„ ê°€ì •í•©ë‹ˆë‹¤.\n",
    "    y_ret_pred = loaded_model.predict(X_predict_2d)\n",
    "\n",
    "    print(f\"âœ… ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ. ì˜ˆì¸¡ëœ ret_prev ê¸¸ì´: {len(y_ret_pred)}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. ì°¨ë¶„ â†’ ë¡œê·¸ ë ˆë²¨ ë³µì›\n",
    "    # logP_pred[t] = logP_true[t-1] + ret_prev_pred[t]\n",
    "    # -------------------------------\n",
    "\n",
    "    # 4-1. ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤ê°€ ì›ë˜ ë°ì´í„°ì—ì„œ ê°€ë¦¬í‚¤ëŠ” ì¸ë±ìŠ¤ ê³„ì‚°\n",
    "    # ì˜ˆì¸¡ëœ ì²« ì‹œì ì˜ ì›ë˜ ì¸ë±ìŠ¤ëŠ” (0 + BEST_SEQ_LEN - 1)\n",
    "    orig_pos_start = BEST_SEQ_LEN - 1\n",
    "    orig_pos_end = orig_pos_start + n_samples # ì˜ˆì¸¡ëœ ë§ˆì§€ë§‰ ì‹œì  ì¸ë±ìŠ¤ + 1\n",
    "\n",
    "    # 4-2. ë³µì›ì— í•„ìš”í•œ ì§ì „ ì‹œì ì˜ ì‹¤ì œ ë¡œê·¸ ë ˆë²¨ ê°’ (log P[t-1])\n",
    "    # ì¸ë±ìŠ¤ ë²”ìœ„: (orig_pos_start - 1) ë¶€í„° (orig_pos_end - 1)ê¹Œì§€\n",
    "    log_prev_seq = y_log_predict.iloc[orig_pos_start - 1 : orig_pos_end - 1].to_numpy()\n",
    "\n",
    "    # 4-3. ì˜ˆì¸¡ëœ log level ê°€ê²© (log P[t]) ë³µì›\n",
    "    y_log_pred = log_prev_seq + y_ret_pred\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. ìµœì¢… ê²°ê³¼ DataFrame ìƒì„± ë° ì €ì¥\n",
    "    # -------------------------------\n",
    "\n",
    "    # ì›ë˜ ë°ì´í„°ì˜ ë‚ ì§œì™€ ë¡œê·¸ ë ˆë²¨ ground truth\n",
    "    date_predict = df_predict.iloc[orig_pos_start : orig_pos_end]['Date'].reset_index(drop=True)\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"Date\": date_predict,\n",
    "        \"log_true\": y_seq_true, \n",
    "        \"log_pred\": y_log_pred,\n",
    "        \"Price_pred\": np.exp(y_log_pred) # ì‹¤ì œ ê°€ê²© ë ˆë²¨ ë³µì› (ë¡œê·¸ì˜ ì—­ë³€í™˜)\n",
    "    }).set_index(\"Date\")\n",
    "\n",
    "    print(\"\\n=== ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ (ë¡œê·¸ ë° ì‹¤ì œ ê°€ê²© ë ˆë²¨ - ì• 5ê°œ) ===\")\n",
    "    print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0597140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸ¯ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ (ë¡œê·¸ ë ˆë²¨ ê¸°ì¤€) ===\n",
      "**RMSE (Root Mean Squared Error)**: 0.005309\n",
      "**MAE (Mean Absolute Error)** : 0.004295\n",
      "**R^2 Score (ê²°ì • ê³„ìˆ˜)** : 0.822022\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ì´ì „ì— ìƒì„±ëœ DataFrameì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (result_df ë³€ìˆ˜ê°€ í˜„ì¬ í™˜ê²½ì— ì¡´ì¬í•œë‹¤ê³  ê°€ì •)\n",
    "\n",
    "# 1. ì‹¤ì œ ê°’(True)ê³¼ ì˜ˆì¸¡ ê°’(Predicted) ì¶”ì¶œ\n",
    "# ë¡œê·¸ ë ˆë²¨ ê¸°ì¤€ìœ¼ë¡œ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "y_true = result_df['log_true'].to_numpy()\n",
    "y_pred = result_df['log_pred'].to_numpy()\n",
    "\n",
    "# 2. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\n",
    "\n",
    "# 2-1. RMSE (Root Mean Squared Error, ì œê³± í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)\n",
    "rmse_log = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# 2-2. MAE (Mean Absolute Error, í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)\n",
    "mae_log = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# 2-3. R^2 Score (Coefficient of Determination, ê²°ì • ê³„ìˆ˜)\n",
    "r2_log = r2_score(y_true, y_pred)\n",
    "\n",
    "# 3. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n=== ğŸ¯ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ (ë¡œê·¸ ë ˆë²¨ ê¸°ì¤€) ===\")\n",
    "print(f\"**RMSE (Root Mean Squared Error)**: {rmse_log:.6f}\")\n",
    "print(f\"**MAE (Mean Absolute Error)** : {mae_log:.6f}\")\n",
    "print(f\"**R^2 Score (ê²°ì • ê³„ìˆ˜)** : {r2_log:.6f}\")\n",
    "print(\"=================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donga7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
