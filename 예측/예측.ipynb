{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea524bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 불러오기 완료.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 파일 경로\n",
    "model_path = \"../버전2(SPY)/modeling/Model/다중회귀_best.joblib\"  \n",
    "\n",
    "# 예측 데이터 파일 경로\n",
    "data_path = \"../예측/SPYlog샘플데이터.csv\"\n",
    "\n",
    "try:\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    print(\"✅ 모델 불러오기 완료.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 오류: 모델 파일 경로를 찾을 수 없습니다: {model_path}\")\n",
    "    # 프로그램 종료 또는 다음 단계로 이동하지 않음\n",
    "except Exception as e:\n",
    "    print(f\"❌ 모델 불러오기 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8131f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 불러오기 완료. 데이터셋 정보:\n",
      "   Unnamed: 0        Date  GC=F_Volume  ^VIX_Volatility  GC=F_Volatility  \\\n",
      "0           0  2025-11-10     5.241747         0.797507         3.947386   \n",
      "1           1  2025-11-11     6.343880         0.565314         3.505566   \n",
      "2           2  2025-11-12     5.981414         0.672944         4.620059   \n",
      "3           3  2025-11-13     5.117994         1.568616         4.174387   \n",
      "4           4  2025-11-14     6.180017         1.497389         5.016617   \n",
      "\n",
      "   SHY_Volatility  SPY_Premium_pct  y_target_log  \n",
      "0        0.029558         0.025857      6.524208  \n",
      "1        0.039222         0.047590      6.526495  \n",
      "2        0.029565         0.036686      6.527051  \n",
      "3        0.029558         0.028242      6.510318  \n",
      "4        0.086174         0.041819      6.510154  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_predict = pd.read_csv(data_path)\n",
    "    print(\"✅ 데이터셋 불러오기 완료. 데이터셋 정보:\")\n",
    "    print(df_predict.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 오류: 데이터셋 파일 경로를 찾을 수 없습니다: {data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 데이터셋 불러오기 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "050a0024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 피처 스케일링 완료. Shape: (7, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 전역 변수 설정 및 데이터 준비\n",
    "# -------------------------------\n",
    "\n",
    "# [중요] 학습 시 최적으로 도출된 seq_len 값을 직접 입력해야 합니다.\n",
    "# 예시에서는 임의의 값으로 설정합니다. 실제 값을 입력해주세요!\n",
    "BEST_SEQ_LEN = 2 \n",
    "\n",
    "# -------------------------------\n",
    "# 1. 전역 변수 설정 및 데이터 준비 (수정된 부분)\n",
    "# -------------------------------\n",
    "\n",
    "price_col = \"y_target_log\"\n",
    "\n",
    "# 'Unnamed: 0', 'y_target_log' 외에 'Date'도 피처에서 제외해야 합니다.\n",
    "# 예측 데이터에 'Date' 칼럼이 있다면 반드시 drop_cols에 포함해야 합니다.\n",
    "drop_cols = [\"Unnamed: 0\", price_col, \"Date\"] \n",
    "\n",
    "# X_predict는 오직 숫자형 피처만 포함해야 합니다.\n",
    "X_predict = df_predict.drop(columns=drop_cols, errors='ignore') \n",
    "y_log_predict = df_predict[price_col]\n",
    "\n",
    "# [중요] X_predict의 모든 칼럼이 숫자형인지 최종 확인\n",
    "# (만약 다른 문자열 피처가 있다면 여기서 오류가 다시 발생할 수 있습니다.)\n",
    "X_predict = X_predict.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# X_predict가 학습 시 사용된 MinMaxScaler로 스케일링되어야 합니다.\n",
    "scaler_seq = MinMaxScaler()\n",
    "\n",
    "# 학습 데이터와 예측 데이터의 피처 이름이 일치하는지 확인해야 합니다.\n",
    "# (Date 칼럼 제거 후)\n",
    "X_predict_scaled = scaler_seq.fit_transform(X_predict.values) \n",
    "\n",
    "print(f\"✅ 피처 스케일링 완료. Shape: {X_predict_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e99a5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 피처 스케일링 완료. Shape: (7, 5)\n",
      "✅ 현재 총 피처 수: 5\n"
     ]
    }
   ],
   "source": [
    "# 1-1. 학습 시 사용된 5개 피처 이름을 여기에 입력해야 합니다.\n",
    "# [사용자 변경 필요]\n",
    "FEATURE_COLUMNS_FOR_PREDICTION = ['GC=F_Volume', '^VIX_Volatility', 'GC=F_Volatility', 'SHY_Volatility', 'SPY_Premium_pct'] \n",
    "# -------------------------------------------------------------\n",
    "\n",
    "price_col = \"y_target_log\"\n",
    "drop_cols = [\"Unnamed: 0\", price_col, \"Date\"] \n",
    "\n",
    "# 1. 'y_target_log' (로그 레벨) 분리\n",
    "y_log_predict = df_predict[price_col]\n",
    "\n",
    "# 2. 피처에서 불필요한 열 제거\n",
    "X_all = df_predict.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# 3. [핵심 수정] 학습에 사용된 5개 피처만 선택\n",
    "#    (FEATURE_COLUMNS_FOR_PREDICTION 리스트를 사용하여 9개 중 5개만 남김)\n",
    "X_predict = X_all[FEATURE_COLUMNS_FOR_PREDICTION] \n",
    "\n",
    "# 4. 숫자형 피처만 최종 확인 (선택된 5개 피처는 모두 숫자형이어야 함)\n",
    "X_predict = X_predict.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# X_predict가 학습 시 사용된 MinMaxScaler로 스케일링되어야 합니다.\n",
    "scaler_seq = MinMaxScaler()\n",
    "\n",
    "# 이제 X_predict의 shape는 (7, 5)가 될 것이며, \n",
    "# 시퀀스 변환 후 (7-2+1=6) 샘플의 shape는 (6, 5*2=10)이 되어 모델 기대치와 일치합니다.\n",
    "X_predict_scaled = scaler_seq.fit_transform(X_predict.values) \n",
    "\n",
    "print(f\"✅ 피처 스케일링 완료. Shape: {X_predict_scaled.shape}\")\n",
    "print(f\"✅ 현재 총 피처 수: {X_predict_scaled.shape[1]}\") # 5여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "877f370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 시퀀스 데이터셋 재구성 완료.\n",
      "   예측 샘플 수: 6\n",
      "   모델 입력 shape: (6, 10)\n",
      "✅ 모델 예측 완료. 예측된 ret_prev 길이: 6\n",
      "\n",
      "=== 최종 예측 결과 (로그 및 실제 가격 레벨 - 앞 5개) ===\n",
      "            log_true  log_pred  Price_pred\n",
      "Date                                      \n",
      "2025-11-11  6.526495  6.533879  688.062366\n",
      "2025-11-12  6.527051  6.532389  687.037840\n",
      "2025-11-13  6.510318  6.502512  666.814325\n",
      "2025-11-14  6.510154  6.510263  672.003450\n",
      "2025-11-17  6.500794  6.500677  665.591945\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리/모듈이 이미 상단에 정의되어 있다고 가정합니다.\n",
    "# 예: import numpy as np, import pandas as pd, loaded_model 변수 존재\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 시퀀스 데이터셋 생성 함수 재정의\n",
    "# -------------------------------\n",
    "def make_seq_dataset_for_reg(X_array, y_array, seq_len):\n",
    "    \"\"\"\n",
    "    X_array: (N, num_features)\n",
    "    y_array: (N,)\n",
    "    seq_len 기간만큼 window를 만들어,\n",
    "      X_seq: (num_samples, seq_len, num_features)\n",
    "      y_seq: (num_samples,)\n",
    "    를 반환합니다. 타깃은 window의 마지막 시점 y.\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    # 예측 데이터의 경우, 모든 시퀀스 생성 가능 시점부터 예측을 수행합니다.\n",
    "    for i in range(len(X_array) - seq_len + 1):\n",
    "        X_list.append(X_array[i : i + seq_len])\n",
    "        # y_array는 예측 시점의 실제 로그 레벨(Ground Truth)입니다.\n",
    "        y_list.append(y_array[i + seq_len - 1]) \n",
    "        \n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. 시퀀스 변환 및 예측 수행\n",
    "# -------------------------------\n",
    "\n",
    "# X_predict_scaled (Shape: (7, 9))와 y_log_predict를 사용합니다.\n",
    "# BEST_SEQ_LEN = 2\n",
    "X_seq_predict, y_seq_true = make_seq_dataset_for_reg(\n",
    "    X_predict_scaled, \n",
    "    y_log_predict.values, \n",
    "    BEST_SEQ_LEN\n",
    ")\n",
    "n_samples = len(X_seq_predict) # 예상 n_samples: 7 - 2 + 1 = 6\n",
    "\n",
    "if n_samples == 0:\n",
    "    print(f\"❌ 오류: 시퀀스 샘플 수가 0입니다. (데이터 길이:{len(X_predict_scaled)} vs BEST_SEQ_LEN:{BEST_SEQ_LEN})\")\n",
    "else:\n",
    "    # 3D (n_samples, seq_len, n_features) → 2D (n_samples, seq_len * n_features)\n",
    "    X_predict_2d = X_seq_predict.reshape(n_samples, -1)\n",
    "    \n",
    "    print(f\"✅ 시퀀스 데이터셋 재구성 완료.\")\n",
    "    print(f\"   예측 샘플 수: {n_samples}\")\n",
    "    print(f\"   모델 입력 shape: {X_predict_2d.shape}\")\n",
    "\n",
    "    # 예측 수행 (차분 값 ret_prev 예측)\n",
    "    # loaded_model은 LinearRegression 모델을 가정합니다.\n",
    "    y_ret_pred = loaded_model.predict(X_predict_2d)\n",
    "\n",
    "    print(f\"✅ 모델 예측 완료. 예측된 ret_prev 길이: {len(y_ret_pred)}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. 차분 → 로그 레벨 복원\n",
    "    # logP_pred[t] = logP_true[t-1] + ret_prev_pred[t]\n",
    "    # -------------------------------\n",
    "\n",
    "    # 4-1. 예측된 시퀀스가 원래 데이터에서 가리키는 인덱스 계산\n",
    "    # 예측된 첫 시점의 원래 인덱스는 (0 + BEST_SEQ_LEN - 1)\n",
    "    orig_pos_start = BEST_SEQ_LEN - 1\n",
    "    orig_pos_end = orig_pos_start + n_samples # 예측된 마지막 시점 인덱스 + 1\n",
    "\n",
    "    # 4-2. 복원에 필요한 직전 시점의 실제 로그 레벨 값 (log P[t-1])\n",
    "    # 인덱스 범위: (orig_pos_start - 1) 부터 (orig_pos_end - 1)까지\n",
    "    log_prev_seq = y_log_predict.iloc[orig_pos_start - 1 : orig_pos_end - 1].to_numpy()\n",
    "\n",
    "    # 4-3. 예측된 log level 가격 (log P[t]) 복원\n",
    "    y_log_pred = log_prev_seq + y_ret_pred\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. 최종 결과 DataFrame 생성 및 저장\n",
    "    # -------------------------------\n",
    "\n",
    "    # 원래 데이터의 날짜와 로그 레벨 ground truth\n",
    "    date_predict = df_predict.iloc[orig_pos_start : orig_pos_end]['Date'].reset_index(drop=True)\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"Date\": date_predict,\n",
    "        \"log_true\": y_seq_true, \n",
    "        \"log_pred\": y_log_pred,\n",
    "        \"Price_pred\": np.exp(y_log_pred) # 실제 가격 레벨 복원 (로그의 역변환)\n",
    "    }).set_index(\"Date\")\n",
    "\n",
    "    print(\"\\n=== 최종 예측 결과 (로그 및 실제 가격 레벨 - 앞 5개) ===\")\n",
    "    print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0597140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 예측 모델 성능 지표 (로그 레벨 기준) ===\n",
      "**RMSE (Root Mean Squared Error)**: 0.005309\n",
      "**MAE (Mean Absolute Error)** : 0.004295\n",
      "**R^2 Score (결정 계수)** : 0.822022\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 이전에 생성된 DataFrame을 사용합니다. (result_df 변수가 현재 환경에 존재한다고 가정)\n",
    "\n",
    "# 1. 실제 값(True)과 예측 값(Predicted) 추출\n",
    "# 로그 레벨 기준으로 성능을 측정합니다.\n",
    "y_true = result_df['log_true'].to_numpy()\n",
    "y_pred = result_df['log_pred'].to_numpy()\n",
    "\n",
    "# 2. 성능 지표 계산\n",
    "\n",
    "# 2-1. RMSE (Root Mean Squared Error, 제곱 평균 제곱근 오차)\n",
    "rmse_log = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# 2-2. MAE (Mean Absolute Error, 평균 절대 오차)\n",
    "mae_log = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# 2-3. R^2 Score (Coefficient of Determination, 결정 계수)\n",
    "r2_log = r2_score(y_true, y_pred)\n",
    "\n",
    "# 3. 결과 출력\n",
    "print(\"\\n=== 예측 모델 성능 지표 (로그 레벨 기준) ===\")\n",
    "print(f\"**RMSE (Root Mean Squared Error)**: {rmse_log:.6f}\")\n",
    "print(f\"**MAE (Mean Absolute Error)** : {mae_log:.6f}\")\n",
    "print(f\"**R^2 Score (결정 계수)** : {r2_log:.6f}\")\n",
    "print(\"=================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donga7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
